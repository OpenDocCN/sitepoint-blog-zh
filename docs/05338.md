# 一个网上搜索者的和服指南

> 原文:[https://www.sitepoint.com/web-scrapers-guide-kimono/](https://www.sitepoint.com/web-scrapers-guide-kimono/)

作为《黑客新闻》的经常读者，我注意到今年早些时候头版上的一条消息，上面写着:“[和服——再也不要写网络刮刀了](https://news.ycombinator.com/item?id=7066479)”虽然它获得了大量的支持，但技术集团很快就注意到了问题，尤其是如果你是一个知道如何编写 scrapers 的开发人员。最大的问题是不直观的 UX，其次是第一个测试版无法像演示视频显示的那样顺利地从网站提取数据项。

我决定在测试前几个月给它，最近我终于有机会这么做了。

和服是一家由 Y-Combinator 支持的初创公司，试图在其他人失败的领域做一些事情。和服专注于为没有 API 的网站创建 API，另一个术语是网络抓取。假设您有一个网站，其中显示了一些您希望在网站或应用程序中动态处理的数据。如果网站没有 API，您可以通过从网站提取数据项，使用和服创建一个 API。

## 合法吗？

和服为[提供了一个 FAQ](https://www.kimonolabs.com/learn/faq#faq-extracting-data-4) 部分，该部分称从公共网站抓取网页“100%合法”，只要你检查`robots.txt`文件，看看他们禁止了哪些 URL 模式。然而，我建议你谨慎行事，因为有些网站可能会带来问题。

一个`robots.txt`是一个文件，给访问网站的爬虫(通常是搜索引擎)指明方向。如果一个网站管理员想要一个页面在像 Google 这样的搜索引擎上可用，他不会不允许机器人出现在`robots.txt`文件中。如果他们不希望有人抓取他们的内容，他们会在服务条款中明确提到。在通过和服创建一个 API 之前，你应该总是查看这些术语。

这方面的一个例子是中等。他们的 [`robots.txt`](https://medium.com/robots.txt) 文件没有提到任何关于他们公开帖子的内容，但是从他们的 [TOS 页面](https://medium.com/policy/medium-terms-of-service-9db0094a1e0f)中引用的以下内容显示你不应该抓取他们(因为这涉及到从他们的 HTML/CSS 中提取数据)。

> 对于网站的其余部分，除非法律允许，否则未经 Medium 明确书面许可，您不得复制、拷贝或重复使用 HTML/CSS、JavaScipt、徽标或视觉设计元素的任何部分。

如果你查看他们网站的 [#BuiltWithKimono 部分](http://builtwith.kimonolabs.com/)，你会注意到一些简单的应用程序。例如，有一个[价格比较 API](https://econsultancy.com/blog/64826-how-to-build-your-own-price-comparison-api-in-30-minutes-with-no-code#i.1hf2kbm1c3ter8) ，它是通过从不同网站的产品页面中提取价格构建的。

让我们继续下去，看看我们如何使用这项服务。

## 我们要做什么？

让我们尝试完成一项任务，同时探索和服。博客碗是一个博客目录，在这里你可以分享和发现博客。用户分享的帖子可以在 [feeds 页面](http://theblogbowl.in/feeds/)上看到。让我们试着从页面中获取一个博客文章列表。

抓取数据时的简单思维过程是解析 HTML(或者用更简单的术语来说，搜索它)并提取我们需要的信息。在这种情况下，让我们尝试获取文章的标题、链接以及博主的姓名和个人资料页面。

## 入门指南

![Sign Up Form](../Images/86557aa2a6650a731c75cd904900a544.png)

当然，第一步是注册。一旦你注册了，选择两个选项来运行和服:通过 Chrome 扩展或 bookmarklet。

## 要报废的暂存项目

我们将从使用 bookmarklet 开始，从我们的基本 URL([http://theblogbowl.in/feeds/](http://theblogbowl.in/feeds/))开始。下一步是选择我们想要存储的项目。在我们的例子中，我们只存储帖子的标题和博客作者的名字。与这些文本相关联的各个链接(或任何其他 HTML 属性)会被和服自动拾取。一旦选择了所需的数据，就可以通过更改视图来检查高级视图或示例数据输出。

![Selecting the Data](../Images/3defa927869fd361722e86e6d459c897.png)

这是你开始注意到过程中一些小问题的地方。做出选择不是很直观，但是你最终应该能够找出正确的过程。单击一个项目后，页面上所有其他类似的项目都会突出显示，您需要通过选择选项旁边出现的一对小图标(勾号和叉号)来指出这些选项是否正确。如果您需要向列表中添加更多项目，请单击顶部的“+”图标，然后重复该过程。

和服让您能够创建集合，并将相似的数据项组合成一个。虽然从 scraper 的角度来看，这并没有什么不同，但它有助于从概念上简化数据，这可能有助于其他人理解您所做的事情。

## 页码

对于任何 web 抓取器来说，管理分页都是一个非常重要的问题。作为开发人员，您要么检查页面的 URL 模式(在我们的例子中是`http://theblogbowl.in/feeds/?p=[page_no]`)并遍历页面，要么保存分页链接并逐个打开它们。自然是前一种方式更好。和服允许分页，你需要点击右上角的图标来激活该功能。

点击按钮或链接，进入下一页。在这个页面中，“>”链接完成了这项工作，所以我们在激活分页特性之后选择该项。

选择完下一页链接后，单击下面截图中的勾号图标。

![Implementing Pagination Data](../Images/45b52c1f272868961c6f78f02a518530.png)

完成后，点击“完成”按钮继续。

虽然看起来和服明白要寻找什么，我将在后面的文章中解释他们分页功能的漏洞。

## 运行铲运机

一旦我们保存了 scraper，我们可以将它设置为定期运行，或者按需运行。在我们的案例中，我们选择了后者。虽然有 92 页，但我把限制设为 500 页，看看效果如何。

![Running the Scraper](../Images/a566868116313e6bca09f1fc2885fc70.png)

## 结果

一旦刮擦任务完成，让我们看看结果。

![Scraping Results](../Images/561043dbd03ffb778bf42b51243b7aa5.png)

尽管我将页面限制为 50 页，但我在大约 18 页时停止了它，以查看结果。他们来了。

![Output ](../Images/4a8c13c7d79c98d61c2a9951b63350ea.png)

我们成功地提取了我们需要的数据。但这是完美的服务吗？

## 什么时候会出问题？

在我们的任务中，我们方便地选择了 next 按钮进行分页。[官方文档](https://www.kimonolabs.com/learn/pagination)提到我们必须将`Next`链接提供给和服的 API 以理解分页。

这意味着和服的分页只有在“下一步”按钮出现时才起作用。这意味着没有“下一步”按钮的网站不能被和服抓取。

例如，[这个网站](http://travelers.bootsnall.com)包含大量信息，页面列表如下所示。但是，没有“下一个”或“上一个”按钮。

## 和服的前景如何？

和服非常适合为单页面应用程序构建 API。如果你需要它抓取不同结构的多个页面，和服可能无法完成。

如果您需要抓取包含大量逻辑的复杂网页，和服不够先进，无法满足您的需求。和服是在不断进化的(毕竟它有 YC 做后盾！)也许有一天“你不用再写一个网络刮刀了。”

在此之前，如果您想承担这些复杂的任务，您只需要依靠您的正则表达式技能和 HTML 解析器！

你有穿和服的经验吗？你认为服务怎么样？

## 分享这篇文章