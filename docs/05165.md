# Diffbot:重复的集合和合并的 API

> 原文:[https://www . site point . com/diff bot-repeated-collections-merged-APIs/](https://www.sitepoint.com/diffbot-repeated-collections-merged-apis/)

在上一篇关于用 Diffbot 分析 SitePoint 作者简介的文章中，我们构建了一个定制的 API，可以自动对作者的作品列表进行分页，并提取他的姓名、简历和一系列带有基本数据(URL、标题和日期戳)的文章。在这篇文章中，我们将提取作者社交网络的链接。

## 介绍

如果你在一个作者的个人资料页面上看他的简历框里的社交网络图标，你会注意到它们各不相同。可以没有，也可以有八个，或者介于两者之间。更糟糕的是，这些链接没有以任何语义上有意义的方式进行分类——它们只是带有图标和 href 属性的链接。

![](../Images/e406ed5a0a8bc8f0805c9a220f3131f3.png)

这使得将它们转化为可提取的模式变得困难，然而这正是我们在这里要做的，因为嘿，谁不喜欢挑战呢？

要进行设置，请阅读并浏览[第一部分](https://www.sitepoint.com/analyze-sitepoint-author-portfolios-diffbot/)。完成后，重新进入开发仪表板。

## 重复收款问题

合乎逻辑的方法是定义一个新的集合，就像帖子一样，但是它的目标是社交网络链接。然后，只需将 href 属性放在每一个上，我们就设置好了，对吗？没有。

观察以下内容:

![](../Images/033d20d0e882fae4380f72331db09116.png)

如你所见，我们得到了所有的社会联系。但是我们得到的都是 X 次，其中 X 是作者简介中的页数。这是因为 Diffbot API 将所有页面的 HTML 连接成一个大页面，我们的收集规则找到了几组社交网络图标链接。

直觉可能会让你在第一页的父集合上使用一个`:first-child`伪元素，但是 API 不是这样工作的。单个页面的 HTML 内容*被*连接起来，是的，但是规则首先在它们上面执行。实际上，只有结果被连接。这就是为什么不可能使用`main:first-child`只针对第一页。同样，目前 Diffbot API 没有任何`:first-page`自定义伪元素，但它们在稍后阶段出现也不是不可能的。那么，我们如何做到这一点？

## 自定义域正则表达式和 API 副本

Diffbot 允许您为同一个 API 端点定义几个自定义规则集，这些规则集因域正则表达式而异。当调用一个 API 端点时，所有匹配 URL 的规则集都被执行，结果被连接起来，并且您得到一个唯一的集合，就好像它都在一个 API 中一样。这也是我们要做的。

### 新旧 API

首先，转到“创建一个规则”并选择一个自定义 API，这样系统会询问您一个名称。输入与第一部分相同的名称(在我的例子中是 AuthorFolio)。输入典型测试 url ( `https://www.sitepoint.com/author/bskvorc/`)并运行测试。然后，将域正则表达式更改为:

```
(http(s)?://)?(.*\.)?sitepoint.com/author/[^/]+/
```

这告诉 API 只将任何作者配置文件的第一页作为目标——它完全忽略分页。

### 定义集合

接下来，定义一个新集合。称之为“社交”，用`.contributor_social li`的选择器给它一个自定义字段。将字段命名为“link”，并给它一个选择器“a”和一个属性过滤器`href`。保存，等待重新加载，注意现在已经提取了四个链接:

![](../Images/7673255d5b9edb00d95390ea65e156dc.png)

### 社交网络名称

但是只有链接有点糟糕，不是吗？如果我们也有一个社交网络名就好了。然而，SitePoint 的设计没有以任何语义上有意义的方式对它们进行分类，所以没有简单的方法来获得网络名称。我们如何解决这个问题？

正则表达式重写过滤器拯救！

自定义字段有三种可用的过滤器:

*   属性:提取 HTML 元素的属性
*   ignore:基于 css 选择器忽略某些 HTML 元素
*   replace:如果正则表达式模式匹配，则用给定内容替换输出内容

我们将使用第三种——在这里阅读更多关于它们的信息[。](https://diffbot.com/dev/customize/help.jsp#tab_filters)

为我们的“社交”系列增加一个新领域。给它命名为“network”、选择器`a`和属性过滤器`href`，这样它就像“link”字段一样提取链接。然后，添加一个新的“替换”过滤器。

SitePoint 作者个人资料可以包含以下社交网络:Google+、Twitter、脸书、Reddit、Youtube、Flickr、Github 和 Linkedin。幸运的是，每一个都有非常简单的 URL 和完整的域名，所以重新定义域名是小菜一碟。正确的正则表达式是`^.*KEYWORD.*$`:

![](../Images/3843738867789020c3c4171749ab4b55.png)

保存，等待重新加载，注意你现在有一个作者的社会链接的良好形式的集合。

![](../Images/7baf661367c0003487e867e8591921fb.png)

## 将 API 整合在一起

最后，让我们一次性获取所有这些数据。根据我们上面所说的，使用 AuthorFolio API 执行对作者页面的调用，现在应该会给我们一个 JSON 响应，其中包含我们到目前为止定义的所有内容，包括第一篇文章中的字段。让我们看看这是不是真的。在您的浏览器中访问以下链接:

```
http://diffbot.com/api/AuthorFolio?token=xxxxxxxxx&url=https://www.sitepoint.com/author/bskvorc/
```

这是我得到的结果:

![](../Images/0f5e43b65c71310ab8e5be539872f92e.png)

如您所见，我们成功地合并了两个 API，并获得了我们想要的所有结果。我们现在可以从任何第三方应用程序随意使用这个 API URL，并拉入作者的作品集，轻松地按日期分组，检测简历中的变化，注册新添加的社交网络，等等。

## 结论

在这篇文章中，我们看到了用 Diffbot 进行可视化爬行的一些更棘手的方面，比如重复的集合和自定义域正则表达式上的重复 API。我们建立了一个端点，允许我们从作者的个人资料中提取有价值的信息，我们学会了如何将这些知识应用到任何类似的情况中。

你用这些技巧爬了一些有趣的东西吗？你遇到什么麻烦了吗？请在下面的评论中告诉我们！

## 分享这篇文章